{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../PreprocessedData/preprocessed_data.csv',sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>343951</th>\n",
       "      <td>1176935779500773376</td>\n",
       "      <td>Ù„Ù…Ø§ ÙŠÙ‚ØµÙˆÙ† Ø¹Ù„ÙŠÙ‡ Ø§ÙˆÙ„ Ù…Ø±Ø© Ù†Ù‚ÙˆÙ„ Ø·ÙŠØ¨ ÙˆØ«Ù‚ØªÙ‡ Ø²Ø§ÙŠØ¯Ø© Ø¨Ø§...</td>\n",
       "      <td>KW</td>\n",
       "      <td>Ù„Ù…Ø§ ÙŠÙ‚ØµÙˆÙ† Ø¹Ù„ÙŠÙ‡ Ø§ÙˆÙ„ Ù…Ø±Ø© Ù†Ù‚ÙˆÙ„ Ø·ÙŠØ¨ ÙˆØ«Ù‚ØªÙ‡ Ø²Ø§ÙŠØ¯Ø© Ø¨Ø§...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270826</th>\n",
       "      <td>915966586175049600</td>\n",
       "      <td>@a_berber07 @MahmoudAttyaAid ÙˆÙ„Ø³Ù‡ Ø§Ù†Øª Ø´ÙˆÙØª Ø­Ø§Ø¬...</td>\n",
       "      <td>EG</td>\n",
       "      <td>[Ù…Ø³ØªØ®Ø¯Ù…] [Ù…Ø³ØªØ®Ø¯Ù…] ÙˆÙ„Ø³Ù‡ Ø§Ù†Øª Ø´ÙˆÙØª Ø­Ø§Ø¬Ø© . . ØªØ±Ø­Ø§Ù„...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75680</th>\n",
       "      <td>962999639183065216</td>\n",
       "      <td>@Dhahi_Khalfan Ù†ÙØ³ Ø§Ù„Ù„ÙŠ Ø³ÙˆØ§Ù‡ ÙˆÙ„Ø¯ Ø³Ù„Ù…Ø§Ù† Ø¨Ø³ Ø¨Ø·Ø±ÙŠ...</td>\n",
       "      <td>QA</td>\n",
       "      <td>[Ù…Ø³ØªØ®Ø¯Ù…] Ù†ÙØ³ Ø§Ù„Ù„ÙŠ Ø³ÙˆØ§Ù‡ ÙˆÙ„Ø¯ Ø³Ù„Ù…Ø§Ù† Ø¨Ø³ Ø¨Ø·Ø±ÙŠÙ‚Ù‡ Ø±Ø§Ù‚...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104454</th>\n",
       "      <td>872882143965437952</td>\n",
       "      <td>Ù…Ø´ Ø¨Ø¹ÙŠØ¯ Ø¨ÙƒØ±Ø© Ù†Ø´ÙˆÙ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø¨ÙŠÙ‚Ø²Ø¯Ø±ÙˆØ§ ÙÙŠ Ø´ÙˆØ§Ø±Ø¹ Ù…ÙƒØ©...</td>\n",
       "      <td>PL</td>\n",
       "      <td>Ù…Ø´ Ø¨Ø¹ÙŠØ¯ Ø¨ÙƒØ±Ø© Ù†Ø´ÙˆÙ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø¨ÙŠÙ‚Ø²Ø¯Ø±ÙˆØ§ ÙÙŠ Ø´ÙˆØ§Ø±Ø¹ Ù…ÙƒØ©...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144674</th>\n",
       "      <td>946128795039420416</td>\n",
       "      <td>@hany_ms ğŸ˜ˆ Ù…Ø§Ù‡Ùˆ ÙŠØ¨Ø¯Ø§Ùˆ Ø¨ÙŠÙƒ Ø§Ù„Ø§ÙˆÙ„ Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡</td>\n",
       "      <td>TN</td>\n",
       "      <td>[Ù…Ø³ØªØ®Ø¯Ù…] Ù…Ø§Ù‡Ùˆ ÙŠØ¨Ø¯Ø§Ùˆ Ø¨ÙŠÙƒ Ø§Ù„Ø§ÙˆÙ„ Ù‡Ù‡</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "343951  1176935779500773376   \n",
       "270826   915966586175049600   \n",
       "75680    962999639183065216   \n",
       "104454   872882143965437952   \n",
       "144674   946128795039420416   \n",
       "\n",
       "                                                     text dialect  \\\n",
       "343951  Ù„Ù…Ø§ ÙŠÙ‚ØµÙˆÙ† Ø¹Ù„ÙŠÙ‡ Ø§ÙˆÙ„ Ù…Ø±Ø© Ù†Ù‚ÙˆÙ„ Ø·ÙŠØ¨ ÙˆØ«Ù‚ØªÙ‡ Ø²Ø§ÙŠØ¯Ø© Ø¨Ø§...      KW   \n",
       "270826  @a_berber07 @MahmoudAttyaAid ÙˆÙ„Ø³Ù‡ Ø§Ù†Øª Ø´ÙˆÙØª Ø­Ø§Ø¬...      EG   \n",
       "75680   @Dhahi_Khalfan Ù†ÙØ³ Ø§Ù„Ù„ÙŠ Ø³ÙˆØ§Ù‡ ÙˆÙ„Ø¯ Ø³Ù„Ù…Ø§Ù† Ø¨Ø³ Ø¨Ø·Ø±ÙŠ...      QA   \n",
       "104454  Ù…Ø´ Ø¨Ø¹ÙŠØ¯ Ø¨ÙƒØ±Ø© Ù†Ø´ÙˆÙ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø¨ÙŠÙ‚Ø²Ø¯Ø±ÙˆØ§ ÙÙŠ Ø´ÙˆØ§Ø±Ø¹ Ù…ÙƒØ©...      PL   \n",
       "144674           @hany_ms ğŸ˜ˆ Ù…Ø§Ù‡Ùˆ ÙŠØ¨Ø¯Ø§Ùˆ Ø¨ÙŠÙƒ Ø§Ù„Ø§ÙˆÙ„ Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡Ù‡      TN   \n",
       "\n",
       "                                        preprocessed_text  \n",
       "343951  Ù„Ù…Ø§ ÙŠÙ‚ØµÙˆÙ† Ø¹Ù„ÙŠÙ‡ Ø§ÙˆÙ„ Ù…Ø±Ø© Ù†Ù‚ÙˆÙ„ Ø·ÙŠØ¨ ÙˆØ«Ù‚ØªÙ‡ Ø²Ø§ÙŠØ¯Ø© Ø¨Ø§...  \n",
       "270826  [Ù…Ø³ØªØ®Ø¯Ù…] [Ù…Ø³ØªØ®Ø¯Ù…] ÙˆÙ„Ø³Ù‡ Ø§Ù†Øª Ø´ÙˆÙØª Ø­Ø§Ø¬Ø© . . ØªØ±Ø­Ø§Ù„...  \n",
       "75680   [Ù…Ø³ØªØ®Ø¯Ù…] Ù†ÙØ³ Ø§Ù„Ù„ÙŠ Ø³ÙˆØ§Ù‡ ÙˆÙ„Ø¯ Ø³Ù„Ù…Ø§Ù† Ø¨Ø³ Ø¨Ø·Ø±ÙŠÙ‚Ù‡ Ø±Ø§Ù‚...  \n",
       "104454  Ù…Ø´ Ø¨Ø¹ÙŠØ¯ Ø¨ÙƒØ±Ø© Ù†Ø´ÙˆÙ Ø§Ù„ÙŠÙ‡ÙˆØ¯ Ø¨ÙŠÙ‚Ø²Ø¯Ø±ÙˆØ§ ÙÙŠ Ø´ÙˆØ§Ø±Ø¹ Ù…ÙƒØ©...  \n",
       "144674                   [Ù…Ø³ØªØ®Ø¯Ù…] Ù…Ø§Ù‡Ùˆ ÙŠØ¨Ø¯Ø§Ùˆ Ø¨ÙŠÙƒ Ø§Ù„Ø§ÙˆÙ„ Ù‡Ù‡  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['preprocessed_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val = train_test_split(df, test_size=0.1, random_state=42, stratify=df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((412342, 4), (45816, 4))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = arabert_tokenizer.tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=tokenize, ngram_range=(1, 2), min_df=2, lowercase=False, token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(lowercase=False, min_df=2, ngram_range=(1, 2),\n",
       "                token_pattern=None,\n",
       "                tokenizer=<function tokenize at 0x000001EA81D64708>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(X_tr['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "816817"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr_tf = tfidf.transform(X_tr['preprocessed_text'])\n",
    "X_val_tf = tfidf.transform(X_val['preprocessed_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, random_state=42, verbose=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearSVC(C=10, dual=True, verbose=True, random_state=42)\n",
    "model.fit(X_tr_tf, X_tr['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5617033350794483\n"
     ]
    }
   ],
   "source": [
    "print(model.score(X_val_tf, X_val['dialect']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = '../models/svm_model.sav'\n",
    "filename2 = '../models/tfidf.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(model, open(filename1, 'wb'))\n",
    "pickle.dump(tfidf, open(filename2, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(filename1, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5617033350794483\n"
     ]
    }
   ],
   "source": [
    "print(loaded_model.score(X_val_tf, X_val['dialect']) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
