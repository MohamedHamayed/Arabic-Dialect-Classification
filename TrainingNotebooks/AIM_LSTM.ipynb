{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from transformers import AutoTokenizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import LSTM, Dense, GRU, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../PreprocessedData/preprocessed_data.csv',sep='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "      <th>preprocessed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7565</th>\n",
       "      <td>980073078909632384</td>\n",
       "      <td>@war7 مظغوط بويمن انفضحت ههههه</td>\n",
       "      <td>IQ</td>\n",
       "      <td>[مستخدم] مظغوط بويمن انفضحت هه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71742</th>\n",
       "      <td>1126485283833249792</td>\n",
       "      <td>@Nor__201 الشرهة واللوم على اللي يدفعون.</td>\n",
       "      <td>QA</td>\n",
       "      <td>[مستخدم] الشرهة واللوم على اللي يدفعون .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74632</th>\n",
       "      <td>1078416878035484800</td>\n",
       "      <td>@moazot2015 @imankais1 هل هذا يعقل؟ ع قولة معز...</td>\n",
       "      <td>QA</td>\n",
       "      <td>[مستخدم] [مستخدم] هل هذا يعقل ؟ ع قولة معزبكم ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193426</th>\n",
       "      <td>842385563193905152</td>\n",
       "      <td>عزيزتي البنت \\nقبل ماتطلبين طلب من اخوك قولي ل...</td>\n",
       "      <td>SA</td>\n",
       "      <td>عزيزتي البنت قبل ماتطلبين طلب من اخوك قولي له ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419286</th>\n",
       "      <td>897409645056327680</td>\n",
       "      <td>@Bash9987 سؤال انته بكامل قواك العقليه؟!اذا كل...</td>\n",
       "      <td>AE</td>\n",
       "      <td>[مستخدم] سؤال انته بكامل قواك العقليه ؟ ! اذا ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "7565     980073078909632384   \n",
       "71742   1126485283833249792   \n",
       "74632   1078416878035484800   \n",
       "193426   842385563193905152   \n",
       "419286   897409645056327680   \n",
       "\n",
       "                                                     text dialect  \\\n",
       "7565                       @war7 مظغوط بويمن انفضحت ههههه      IQ   \n",
       "71742            @Nor__201 الشرهة واللوم على اللي يدفعون.      QA   \n",
       "74632   @moazot2015 @imankais1 هل هذا يعقل؟ ع قولة معز...      QA   \n",
       "193426  عزيزتي البنت \\nقبل ماتطلبين طلب من اخوك قولي ل...      SA   \n",
       "419286  @Bash9987 سؤال انته بكامل قواك العقليه؟!اذا كل...      AE   \n",
       "\n",
       "                                        preprocessed_text  \n",
       "7565                       [مستخدم] مظغوط بويمن انفضحت هه  \n",
       "71742            [مستخدم] الشرهة واللوم على اللي يدفعون .  \n",
       "74632   [مستخدم] [مستخدم] هل هذا يعقل ؟ ع قولة معزبكم ...  \n",
       "193426  عزيزتي البنت قبل ماتطلبين طلب من اخوك قولي له ...  \n",
       "419286  [مستخدم] سؤال انته بكامل قواك العقليه ؟ ! اذا ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset=['preprocessed_text'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"aubmindlab/bert-base-arabertv02-twitter\"\n",
    "arabert_tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = arabert_tokenizer.encode(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokenized_text'] = df['preprocessed_text'].apply(lambda x: tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max([len(sentence) for sentence in df['tokenized_text']])\n",
    "df['indexed_text'] = [([arabert_tokenizer.pad_token_id] * (max_len - len(sentence))) + sentence for sentence in df['tokenized_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df['dialect'] = le.fit_transform(df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>dialect</th>\n",
       "      <th>preprocessed_text</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>indexed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>367007</th>\n",
       "      <td>1079201073137680384</td>\n",
       "      <td>@Q8Ping @latifaalsaeedan @danaalthuwaikh الله ...</td>\n",
       "      <td>6</td>\n",
       "      <td>[مستخدم] [مستخدم] [مستخدم] الله يخليكم تعلموا ...</td>\n",
       "      <td>[2, 64, 8465, 66, 64, 8465, 66, 64, 8465, 66, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123550</th>\n",
       "      <td>499858668712513600</td>\n",
       "      <td>بيحكو عنك ,,, وهما ناسيين حالهم ,, \\n\\nاتذكر ح...</td>\n",
       "      <td>11</td>\n",
       "      <td>بيحكو عنك , , وهما ناسيين حالهم , , اتذكر حالك...</td>\n",
       "      <td>[2, 1268, 16907, 185, 21619, 18, 18, 7416, 754...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136690</th>\n",
       "      <td>845236338198806528</td>\n",
       "      <td>شو الواحد بدو يعلق على هاد الغبي https://t.co/...</td>\n",
       "      <td>15</td>\n",
       "      <td>شو الواحد بدو يعلق على هاد الغبي [رابط]</td>\n",
       "      <td>[2, 9016, 4332, 41954, 19306, 323, 9237, 580, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338424</th>\n",
       "      <td>1040596257365024768</td>\n",
       "      <td>@Hameeda_W حسسني انهم علماء ورواة احاديث ومتخص...</td>\n",
       "      <td>6</td>\n",
       "      <td>[مستخدم] حسسني انهم علماء ورواة احاديث ومتخصصي...</td>\n",
       "      <td>[2, 64, 8465, 66, 63202, 5014, 6838, 5844, 761...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75548</th>\n",
       "      <td>968320729426092032</td>\n",
       "      <td>@Fares_s44 @DemaQtr @hassanalishaq73 @neno_515...</td>\n",
       "      <td>12</td>\n",
       "      <td>[مستخدم] [مستخدم] [مستخدم] [مستخدم] ياخي سبحان...</td>\n",
       "      <td>[2, 64, 8465, 66, 64, 8465, 66, 64, 8465, 66, ...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         id  \\\n",
       "367007  1079201073137680384   \n",
       "123550   499858668712513600   \n",
       "136690   845236338198806528   \n",
       "338424  1040596257365024768   \n",
       "75548    968320729426092032   \n",
       "\n",
       "                                                     text  dialect  \\\n",
       "367007  @Q8Ping @latifaalsaeedan @danaalthuwaikh الله ...        6   \n",
       "123550  بيحكو عنك ,,, وهما ناسيين حالهم ,, \\n\\nاتذكر ح...       11   \n",
       "136690  شو الواحد بدو يعلق على هاد الغبي https://t.co/...       15   \n",
       "338424  @Hameeda_W حسسني انهم علماء ورواة احاديث ومتخص...        6   \n",
       "75548   @Fares_s44 @DemaQtr @hassanalishaq73 @neno_515...       12   \n",
       "\n",
       "                                        preprocessed_text  \\\n",
       "367007  [مستخدم] [مستخدم] [مستخدم] الله يخليكم تعلموا ...   \n",
       "123550  بيحكو عنك , , وهما ناسيين حالهم , , اتذكر حالك...   \n",
       "136690            شو الواحد بدو يعلق على هاد الغبي [رابط]   \n",
       "338424  [مستخدم] حسسني انهم علماء ورواة احاديث ومتخصصي...   \n",
       "75548   [مستخدم] [مستخدم] [مستخدم] [مستخدم] ياخي سبحان...   \n",
       "\n",
       "                                           tokenized_text  \\\n",
       "367007  [2, 64, 8465, 66, 64, 8465, 66, 64, 8465, 66, ...   \n",
       "123550  [2, 1268, 16907, 185, 21619, 18, 18, 7416, 754...   \n",
       "136690  [2, 9016, 4332, 41954, 19306, 323, 9237, 580, ...   \n",
       "338424  [2, 64, 8465, 66, 63202, 5014, 6838, 5844, 761...   \n",
       "75548   [2, 64, 8465, 66, 64, 8465, 66, 64, 8465, 66, ...   \n",
       "\n",
       "                                             indexed_text  \n",
       "367007  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "123550  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "136690  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "338424  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "75548   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val = train_test_split(df, test_size=0.1, random_state=42, stratify=df['dialect'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((412342, 6), (45816, 6))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X_tr.reset_index().drop(columns='index')\n",
    "X_val = X_val.reset_index().drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataGenerator(keras.utils.all_utils.Sequence):\n",
    "    def __init__(self, sequences, preds, sequence_length, vocab_size, num_classes, batch_size=32, shuffle=True):\n",
    "        self.batch_size = batch_size\n",
    "        self.sequences = sequences\n",
    "        self.preds = preds\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.num_classes = num_classes\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.sequences) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "        sequences_batch = [self.sequences[k] for k in indexes]\n",
    "        preds_batch = [self.preds[k] for k in indexes]\n",
    "\n",
    "        X = np.array(sequences_batch)\n",
    "        y = keras.utils.np_utils.to_categorical(preds_batch, num_classes=self.num_classes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.sequences))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "num_classes = 18\n",
    "\n",
    "params = {\n",
    "  'sequence_length': max_len,\n",
    "  'vocab_size': arabert_tokenizer.vocab_size,\n",
    "  'num_classes':num_classes,\n",
    "  'batch_size': batch_size,\n",
    "  'shuffle': True\n",
    "}\n",
    "\n",
    "train_generator = TextDataGenerator(X_tr['indexed_text'], X_tr['dialect'], **params)\n",
    "val_generator = TextDataGenerator(X_val['indexed_text'], X_val['dialect'], **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_model(sequence_length, vocab_size, num_classes, layer_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size, 128, input_length=sequence_length, trainable=True))\n",
    "    model.add(LSTM(layer_size))#, recurrent_dropout=0.1, dropout=0.1\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM_model(max_len, arabert_tokenizer.vocab_size, num_classes, 128)\n",
    "model.compile(loss='categorical_crossentropy', metrics=['acc'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('../models/lstm_wts.hdf5', save_best_only=True, monitor='val_loss', mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "805/805 [==============================] - 4091s 5s/step - loss: 1.9520 - acc: 0.3811 - val_loss: 1.6473 - val_acc: 0.4855\n",
      "Epoch 2/4\n",
      "805/805 [==============================] - 3565s 4s/step - loss: 1.4529 - acc: 0.5456 - val_loss: 1.5528 - val_acc: 0.5214\n",
      "Epoch 3/4\n",
      "805/805 [==============================] - 3238s 4s/step - loss: 1.2483 - acc: 0.6118 - val_loss: 1.5836 - val_acc: 0.5173\n",
      "Epoch 4/4\n",
      "805/805 [==============================] - 2970s 4s/step - loss: 1.1086 - acc: 0.6554 - val_loss: 1.6501 - val_acc: 0.5132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a88e7f1c48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_generator, steps_per_epoch=len(train_generator), epochs=4, callbacks=[checkpoint], validation_data=val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
